Submission ID,Method Type, Number of Ligands, Kendalls Tau, Kendalls Tau Error, Spearman's Rho, Spearman's Rho Error, Matthews Correlation Coefficient,isAnonymous,Submission ID,Last Name,First Name,Organization,PI Name,Method Name,Software,Parameters,Method,Manual Intervention,Machine Learning,challenge_type
cbfn8,ligand_based_scoring,459,0.34,0.03,0.49,0.04,all_binders,0,cbfn8,bonvin,alexandre,"utrecht university, the netherlands",alexandre bonvin,cathepsin-specific ligand-similarity based prediction,"chemminer, libsvm 3.21","atom pair based ligand similarity   for nu-svr, epsilon = 0.679673, obj = -1856.185741, rho = -6.279170, nsv = 1065, nbsv = 772","we used bindingdb.org to get 1839 ic50s for cathepsin-s as our training data.  we used chemminer to calculate atom pair based ligand similarity between 459 d3r ligands  and the 1839 training ligands, and the ligand similairty between 1839 training ligands. we  trained nu-svr using these similarities to predict log(ic50) for the 459 d3r ligands.",no, Yes ,ligand_based_scoring
tdcvf,ligand_based_scoring,459,0.54,0.03,0.72,0.03,all_binders,0,tdcvf,evangelidis,thomas,uochb & ceitec,thomas evangelidis,deepscaffopt_onlyecfpl_nolossweights,deepscaffopt,only ecfpl fingerprints (ecfp with 8192 bits) without weights in the loss function were used in this protocol.,"deepscaffopt algorithm (still unpublished) trains multiple deep neural netwroks (dnns) using up to 6 different descriptors (ecfpl, fcfpl, rdk5, 2dpp, ergfp, mol2vec). each dnn is trained using as training set all ligands with binding affinities deposited in chembl for this particular receptor. only one descriptor is used to train each dnn. then the best dnns are selected automatically based on some empirical criteria and are combined to give a meta-predictor model. many meta-predictor models are generated, each from a slightly different combination of dnns. from the ensemble of different meta-predictor scorings, only the meta-predictor scoring that is closer to the average scores is retained.",no, Yes ,ligand_based_scoring
bwzzh,ligand_based_scoring,459,-0.04,0.03,-0.06,0.05,all_binders,0,bwzzh,touzeau,boris,academia sinica,dr jung-hsin lin,boris,open babel 2.4.1/chimera alpha version 1.14/pafnucy version 1.0,grid resolution of 1a,"standard approach, by training a convolutional layer on ~10k compounds binding affinities, i obtained a model that i twisted the architecture somewhat to obtain a new model (different from the original one)  i used it to rank the ligands",no, Yes ,ligand_based_scoring
yf3ro,ligand_based_scoring,455,0.38,0.03,0.54,0.04,all_binders,0,yf3ro,bohmann,jonathan,southwest research institute,medicinal and process chemistry,cndo-eeva-backpropagation,"openbabel 2.3.90   cndo program, pople and bevridge (1970) fortran code in ""approximate molecular orbital theory"", mcgraw-hill, new york, 1970.    gnu fortran (ubuntu/linaro 4.8.2-19ubuntu1) 4.8.2   in-house pls regression code",n/a,"a qsar model, based on the gc3 cats dataset as a training set, was developed using  the eeva descriptor approach of tuppurainen and ruuskanen. the 3d geometries of  the ligands were created  with openbabel 2.3.90 from the provided smiles strings, and optimized with the mmff94 forcefield (n=20000 steps)  with the oboptimize program.  a modified version of the original pope and bevride  fortran program was coded to create eeva descriptors from molecular orbital energies.  we used this cndo-eeva code to create  eeva descriptors for each ligand in the gc3 and gc4 sets, using cndo molecular orbital eneriges calculated from  the mmff94-optimized ligand geometries.   the molecule eeva descriptors from the gc3 cats set  were combined with corresponding ic50 values to make a training set for a simple back-propagation single-layer neural network.  the network was trained using 11 hidden neurons and  one output neuron, with an initial learing rate of 0.1 for all neurons.  this neural network was used for predicting    ic50's for the gc4 target set.  eeva reference  kari tuppurainen, juhani ruuskanen,  electronic eigenvalue (eeva) a new qsar/qspr descriptor for electronic substituent effects based on molecular orbital energies. a qsar approach to the ah receptor binding affinity of polychlorinated biphenyls (pcbs), dibenzo-p-dioxins (pcdds) and dibenzofurans (pcdfs),  chemosphere,  volume 41, issue 6,  2000,  pages 843-848,  issn 0045-6535,  https//doi.org/10.1016/s0045-6535(99)00525-1.  =======",no, Yes ,ligand_based_scoring
d7b6y,ligand_based_scoring,459,-0.04,0.03,-0.06,0.05,all_binders,0,d7b6y,touzeau,boris,academia sinica,dr jung-hsin lin,boris,open babel 2.4.1/chimera alpha version 1.14/pafnucy version 1.0,grid resolution of 1a,"standard approach, by training a convolutional layer on ~10k compounds binding affinities, i obtained a model that i twisted the architecture somewhat to obtain a new model (different from the original one)  i used it to rank the ligands",no, Yes ,ligand_based_scoring
tsncn,ligand_based_scoring,455,0.28,0.03,0.41,0.04,all_binders,0,tsncn,bohmann,jonathan,southwest research institute,medicinal and process chemistry,cndo-eeva-pls,"openbabel 2.3.90   cndo program, pople and bevridge (1970) fortran code in ""approximate molecular orbital theory"", mcgraw-hill, new york, 1970.    gnu fortran (ubuntu/linaro 4.8.2-19ubuntu1) 4.8.2   in-house pls regression code",n/a,"a qsar model, based on the gc3 cats dataset as a training set, was developed using  the eeva descriptor approach of tuppurainen and ruuskanen. the 3d geometries of  the ligands were created  with openbabel 2.3.90 from the provided smiles strings, and optimized with the mmff94 forcefield (n=20000 steps)  with the oboptimize program.  a modified version of the original pope and bevride  fortran program was coded to create eeva descriptors from molecular orbital energies.  we used this cndo-eeva code to create  eeva descriptors for each molecule, using cndo molecular orbital eneriges calculated from  the optimized ligand geometries.   the molecule eeva descriptors from the gc3 cats set  were combined with corresponding ic50 values in a plsregression model, creating linear coefficients   for predicting ic50's from eeva descriptors. this qsar pls model was validated with the leave one-out-.    the pls-generated qsar model was applied to the gc4 cats score prediction set, creating ligand-based prediction scores.   eeva reference  kari tuppurainen, juhani ruuskanen,  electronic eigenvalue (eeva) a new qsar/qspr descriptor for electronic substituent effects based on molecular orbital energies. a qsar approach to the ah receptor binding affinity of polychlorinated biphenyls (pcbs), dibenzo-p-dioxins (pcdds) and dibenzofurans (pcdfs),  chemosphere,  volume 41, issue 6,  2000,  pages 843-848,  issn 0045-6535,  https//doi.org/10.1016/s0045-6535(99)00525-1.  =======",no, No ,ligand_based_scoring
2v4fk,ligand_based_scoring,459,0.52,0.03,0.7,0.03,all_binders,0,2v4fk,evangelidis,thomas,uochb & ceitec,thomas evangelidis,deepscaffopt_onlyfcfpl_nolossweights,deepscaffopt,only fcfpl fingerprints (fcfp with 8192 bits) without weights in the loss function were used in this protocol.,"deepscaffopt algorithm (still unpublished) trains multiple deep neural netwroks (dnns) using up to 6 different descriptors (ecfpl, fcfpl, rdk5, 2dpp, ergfp, mol2vec). each dnn is trained using as training set all ligands with binding affinities deposited in chembl for this particular receptor. only one descriptor is used to train each dnn. then the best dnns are selected automatically based on some empirical criteria and are combined to give a meta-predictor model. many meta-predictor models are generated, each from a slightly different combination of dnns. from the ensemble of different meta-predictor scorings, only the meta-predictor scoring that is closer to the average scores is retained.",no, Yes ,ligand_based_scoring
t7nzw,ligand_based_scoring,459,0.35,0.03,0.49,0.04,all_binders,1,t7nzw,,,,,qsar_machine_learning,python/scikit-learn/rdkit/mordred/pandas/numpy/matplotlib,fingerprint tanimoto similarity threshold 0.4,"we used molecular descriptor and fingerprint as input features to construct qsar moldel by machine learning .  compounds information with pchembl value for specific target(cats or bace) was downloaded from chembl database.  compounds with fingerprint tanimoto similarity above 0.4 threshold compared to target compounds were chosen as training dataset.  molecular descriptor was calculated by mordred package. ecfp4 fingerprint was calculated by rdkit.  both of them together were used as input feature vectors to construct qsar model.  several machine learning s were tested, such as svm, randomforest, mlp, nearestneighbors, gaussianprogress.  model with the best performance was selected to predict the ic50 activity for target compounds.  the prediction result was subbmited directly without further modification.",no, Yes,ligand_based_scoring
wrrvx,ligand_based_scoring,459,-0.11,0.03,-0.16,0.05,all_binders,0,wrrvx,brown,benjamin,vanderbilt university,jens meiler,bcl standard ann qsar,"bcl v3.5, corina v4.1.0","as described in doi 10.1007/s10822-016-9895-2 and doi 10.1007/s10822-015-9893-9 with the inclusion of several additional descriptors - 2dasign11(atom_hydrophobicternary), 2dasign11(atom_hbonddonorternary), 3dasign24(atom_hydrophobicternary), 3dasign24(atom_hbonddonorternary).",qsar models built with an ann as described in doi 10.1007/s10822-015-9893-9,no, Yes ,ligand_based_scoring
fghai,ligand_based_scoring,459,-0.04,0.03,-0.06,0.05,all_binders,0,fghai,touzeau,boris,academia sinica,dr jung-hsin lin,boris,open babel 2.4.1/chimera alpha version 1.14/pafnucy version 1.0,grid resolution of 1a,"standard approach, by training a convolutional layer on ~10k compounds binding affinities, i obtained a model that i twisted the architecture somewhat to obtain a new model (different from the original one)  i used it to rank the ligands for this one, i used the protein structure as a whole instead of extracting the as (defined as 8a around the ligand --> 2hhn pdb files)",no, Yes ,ligand_based_scoring
be0m5,ligand_based_scoring,459,0.52,0.03,0.7,0.03,all_binders,0,be0m5,evangelidis,thomas,uochb & ceitec,thomas evangelidis,deepscaffopt_onlyfcfpl_lossweights,deepscaffopt,only fcfpl fingerprints (fcfp with 8192 bits) and weights in the loss function were used in this protocol.,"deepscaffopt algorithm (still unpublished) trains multiple deep neural netwroks (dnns) using up to 6 different descriptors (ecfpl, fcfpl, rdk5, 2dpp, ergfp, mol2vec). each dnn is trained using as training set all ligands with binding affinities deposited in chembl for this particular receptor. only one descriptor is used to train each dnn. then the best dnns are selected automatically based on some empirical criteria and are combined to give a meta-predictor model. many meta-predictor models are generated, each from a slightly different combination of dnns. from the ensemble of different meta-predictor scorings, only the meta-predictor scoring that is closer to the average scores is retained.",no, Yes ,ligand_based_scoring
iiobx,ligand_based_scoring,459,0.26,0.03,0.37,0.04,all_binders,0,iiobx,shamsara,jamal,"mashhad unicversity of medical sciences, mashhad, iran",jamal shamsara,random forest,scikit0.20.1,"number of descriptors,50","a random forest model was trained on  a large dataset of cathepsin_s inhibitors retrieved from chembl, after necessary curation. after external and internal validation the model was used to predict the activity of the new dataset.",no, Yes,ligand_based_scoring